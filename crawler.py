import requests
from bs4 import BeautifulSoup

BASE_URL = "https://lpjh.ylc.edu.tw"
HEADERS = {"User-Agent": "Mozilla/5.0"}

# å´™èƒŒåœ‹ä¸­åˆ†é¡å°æ‡‰
CATEGORY_URLS = {
    "æ ¡å‹™å¸ƒå‘Šæ¬„": f"{BASE_URL}/latest-news",
    "å…§éƒ¨å…¬å‘Š": f"{BASE_URL}/internal-news",
    "çå­¸é‡‘å…¬å‘Š": f"{BASE_URL}/scholarship",
    "å…¬æ–‡è½‰çŸ¥": f"{BASE_URL}/announcements",
    "æ‹›ç”Ÿå°ˆå€": f"{BASE_URL}/admissions",
    "æ•™å‹™è™•å…¬å‘Š": f"{BASE_URL}/academics",
    "å­¸å‹™è™•å…¬å‘Š": f"{BASE_URL}/students-affairs",
    "èª²å¾Œç¤¾åœ˜": f"{BASE_URL}/students-affairs",
}

def full_url(href):
    if not href:
        return None
    if href.startswith("http"):
        return href
    if href.startswith("/"):
        return BASE_URL + href
    return f"{BASE_URL}/{href}"

def fetch_page_items(url):
    """æŠ“å–å…¬å‘Šï¼šæ—¥æœŸ + æ¨™é¡Œ + é€£çµï¼ˆæ­£ç¢ºç‰ˆæœ¬ï¼‰"""
    try:
        r = requests.get(url, timeout=5, headers=HEADERS)
    except:
        return []

    soup = BeautifulSoup(r.text, "html.parser")
    items = []

    # ğŸ”¥ å´™èƒŒåœ‹ä¸­ä½¿ç”¨ <tr> ä¾†æ”¾å…¬å‘Š
    rows = soup.select("table tbody tr")

    for row in rows:
        date_td = row.find("td", class_="news-date")
        a = row.find("a")

        if not a:
            continue

        date = date_td.get_text(strip=True) if date_td else ""
        title = a.get_text(strip=True)
        href = a["href"]

        items.append({
            "title": f"{date} {title}",
            "url": full_url(href)
        })

    return items

def search_school(category, keyword=""):
    url = CATEGORY_URLS.get(category)
    if not url:
        return []

    items = fetch_page_items(url)

    # é—œéµå­—æœå°‹
    if keyword:
        items = [i for i in items if keyword in i["title"]]

    # ç„¡çµæœå›é è¨­é …
    if not items:
        return [{
            "title": f"ç›®å‰æŸ¥ç„¡ã€Œ{category}ã€ç›¸é—œè³‡è¨Šã€‚",
            "url": None
        }]

    return items[:10]
